from bs4 import BeautifulSoup
import requests
from datetime import datetime, timedelta
from dateutil import parser
import pandas as pd

class NewsExtractor:
    def __init__(self, day_limit):
        self.title_list = []
        self.link_list = []
        self.date_list = []
        self.day_limit = day_limit

    def read_web(self, url, news_name, news_class=None):
        response = requests.get(url)
        html = response.text
        soup = BeautifulSoup(html, 'html.parser')
        if news_class == None:
            news_list = soup.find_all(news_name)
        else:
            news_list = soup.find_all(news_name, class_=news_class)
        return news_list

    def extract_web(self, news_list, title_name, link_name, link_class, time_name,
                    title_class=None, source_link=None, time_class=None):
        # check all news and extract title, link and date遍历新闻列表项，提取新闻标题、链接和时间
        for news_item in news_list:
            # extract title
            if title_class is None:
                a_tag = news_item.find(title_name)
            else:
                a_tag = news_item.find(title_name, title_class)
            title = a_tag.get_text(strip=True)

            # extract link
            links = news_item.find_all(link_name)
            if len(links) > 1:
                link = []
                for lk in links:
                    if link_class in lk.attrs:
                        if len(link) < len(lk[link_class]):
                            link = lk[link_class]

            else:
                if link_class is None:
                    link = news_item.find(link_name)
                else:
                    link = news_item.find(link_name)[link_class]
            if 'https' not in link:
                link = source_link + link

            # extract date
            if time_class is not None:
                date_element = news_item.find(time_name, class_=time_class)
            else:
                date_element = news_item.find(time_name)
            date = date_element.get_text(strip=True) if date_element else None

            # obtain current date
            current_time = datetime.now()
            current_time = current_time.date()
            # set time limitation
            time_limit = current_time - timedelta(days= self.day_limit)

            #
            # use dateutil.parser to analyze timestamp
            try:
                try:
                    news_time = parser.parse(date)
                    news_time = datetime.date(news_time)
                except:
                    date_end_index = date.find('|')
                    if date_end_index != -1:
                        date = date[:date_end_index].strip()
                    news_time = parser.parse(date)
                    news_time = datetime.date(news_time)
            except:
                news_time = time_limit - timedelta(days=1)
                print('there is something wrong in date')
                print(f"Title: {title}")
                print(f"Link: {link}")
                print("-" * 50)
            # news_time = datetime.strptime(date, '%Y-%m-%d').date()

            # if news is released before time limitation, then print it
            if news_time >= time_limit:
                # 打印提取的信息
                print(f"Title: {title}")
                print(f"Link: {link}")
                print(f"Date: {news_time}")
                print("-" * 50)
                self.title_list.append(title)
                self.link_list.append(link)
                self.date_list.append(news_time)


    def batch_get_news(self, path, sheetname):
        df = pd.read_excel(path, sheet_name= sheetname)
        for index, row in df.iterrows():
            print(f'index: {index}')
            url = row['url']
            news_name = row['news_name']
            news_class = row['news_class']
            a = row.isna()
            if a['news_class']:
                #print('news_class is None')
                news_class = None
            news_list = self.read_web(url, news_name, news_class)
            title_name = row['title_name']
            link_name = row['link_name']
            link_class = row['link_class']
            time_name = row['time_name']
            title_class = row['title_class']
            source_link = row['source_link']
            time_class = row['time_class']
            if a['title_class']:
                title_class = None
            if a['source_link']:
                source_link = None
            if a['time_class']:
                time_class = None
            self.extract_web(news_list, title_name, link_name, link_class, time_name,
                        title_class, source_link, time_class)

        news_results = {}
        news_results['Link'] = self.link_list
        news_results['Title'] = self.title_list
        news_results['News_date'] = self.date_list

        df1 = pd.DataFrame(news_results)
        # df1.to_excel('new_method_results/news_rs.xlsx')
        return news_list, df1


if __name__ == "__main__":
    # list of websites and key features
    day_limit = 1
    NE = NewsExtractor(day_limit)
    news_list, df = NE.batch_get_news(r'websites.xlsx', 'Sheet1')

